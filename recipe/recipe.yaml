context:
  name: xformers
  version: "0.0.30"
  build_number: 0
  cuda_version: ${{ env.get("CONDA_OVERRIDE_CUDA", default="None")}}
  cuda: ${{ "enabled" if cuda_version != "None" else "disabled" }}
  cuda_build_string: cuda_${{ cuda_version | version_to_buildstring }}
  string_prefix: ${{ cuda_build_string if cuda ==  "enabled" else "cpu_" }}

package:
  name: ${{ name|lower }}
  version: ${{ version }}

source:
  - url: https://pypi.io/packages/source/x/xformers/xformers-${{ version }}.tar.gz
    sha256: a12bf3eb39e294cdbe8a7253ac9b665f41bac61d6d98df174e34ef7bdb6f2fc4
  - url: https://raw.githubusercontent.com/NVIDIA/cutlass/main/LICENSE.txt
    sha256: 80a7a18b73d41f64dd9ca881af35938f8de88b18c728703251f4c94d1299884d
    file_name: third_party/cutlass/LICENSE.txt
  - url: https://raw.githubusercontent.com/Dao-AILab/flash-attention/main/LICENSE
    sha256: 8c9ccb96c065e706135b6cbad279b721da6156e51f3a5f27c6b3329af9416d73
    file_name: third_party/flash-attention/LICENSE

build:
  number: ${{ build_number }}
  skip: win or cuda_compiler_version == "11.8"
  string: ${{ string_prefix }}py${{ python | version_to_buildstring }}h${{ hash }}_${{ build_number }}
  variant:
    use_keys:
      # use cuda from the variant config, e.g. to build multiple CUDA variants
      - ${{ "cuda" if cuda == "enabled" }}
    # this will down-prioritize the cuda variant versus other variants of the package
    down_prioritize_variant: ${{ 1 if cuda == "enabled" else 0 }}
  script:
    file: build
    env:
      cuda_compiler_version: ${{ cuda_version | default('None') }}
      package_version: ${{ version }}

requirements:
  build:
    - if: build_platform != target_platform
      then:
        - python
        - cross-python_${{ target_platform }}
        - pytorch >=2.7

        - if: match(cuda_version, ">=12")
          then:
            - cuda-driver-dev
            - cuda-cudart-dev
            - cuda-nvrtc-dev
            - cuda-nvtx-dev
            - cuda-nvml-dev
            - libcublas-dev
            - libcufft-dev
            - libcurand-dev
            - libcusolver-dev
            - libcusparse-dev

    - ${{ compiler('cxx') }}
    - ${{ stdlib('c') }}
    - git

    - if: cuda == "enabled"
      then:
        - ${{ compiler('cuda') }}
        - cuda-version ==${{ cuda_version }}

  host:
    - python
    - pip
    - setuptools
    - ${{ "pytorch * cuda*" if cuda == "enabled" }}
    - ${{ "pytorch * cpu*" if cuda == "disabled" }}
    - pytorch

    - if: cuda == "enabled"
      then:
        - cuda-version ==${{ cuda_version }}

    - if: match(cuda_version, ">=12")
      then:
        - cuda-driver-dev
        - cuda-cudart-dev
        - cuda-nvrtc-dev
        - cuda-nvtx-dev
        - cuda-nvml-dev
        - libcublas-dev
        - libcufft-dev
        - libcurand-dev
        - libcusolver-dev
        - libcusparse-dev
  run:
    - python
    - numpy
    - pyre-extensions >=0.0.29
    - ${{ "pytorch * cuda*" if cuda == "enabled" }}
    - ${{ "pytorch * cpu*" if cuda == "disabled" }}

  ignore_run_exports:
    # not identical to list of host deps; we do need cuda-cudart,
    # cuda-driver-dev & cuda-nvml-dev have no run-exports
    from_package:
      - if: match(cuda_version, ">=12")
        then:
          - cuda-nvrtc-dev
          - cuda-nvtx-dev
          - libcublas-dev
          - libcufft-dev
          - libcurand-dev
          - libcusolver-dev
          - libcusparse-dev

tests:
  - python:
      imports:
        - xformers
      pip_check: true
  - script:
      - python -m xformers.info

about:
  license: BSD-3-Clause AND Apache-2.0
  license_file:
    - LICENSE
    - third_party/cutlass/LICENSE.txt
    - third_party/flash-attention/LICENSE
    - third_party/sputnik/LICENSE
  summary: "XFormers: A collection of composable Transformer building blocks."
  homepage: https://facebookresearch.github.io/xformers/
  repository: https://github.com/facebookresearch/xformers

extra:
  recipe-maintainers:
    - jan-janssen
    - h-vetinari
