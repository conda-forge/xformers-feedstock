{% set name = "xformers" %}
{% set version = "0.0.26.post1" %}
{% set build_num = 0 %}

{% if cuda_compiler_version is not defined or cuda_compiler_version == "None" %}
{% set build_num = build_num + 1000 %}
{% endif %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  - url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/xformers-{{ version }}.tar.gz
    sha256: 1d14b5f999ede649198379b0470ebdd25007ba224ae336ef958124158a6de8b1
  - url: https://raw.githubusercontent.com/NVIDIA/cutlass/main/LICENSE.txt
    sha256: 6fc6ad419e4d26571a14c7c4d26b65345865c20dd8686ddcf5e8673f54d3d233
    folder: third_party/cutlass
  - url: https://raw.githubusercontent.com/Dao-AILab/flash-attention/main/LICENSE
    sha256: 8c9ccb96c065e706135b6cbad279b721da6156e51f3a5f27c6b3329af9416d73
    folder: third_party/flash-attention

build:
  number: {{ build_num }}
  string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ build_num }}  # [cuda_compiler_version != "None"]
  string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ build_num }}                                                # [cuda_compiler_version == "None"]
  skip: true  # [win]
  skip: true  # [cuda_compiler_version == "10.2"]
  skip: true  # [cuda_compiler_version == "11.0"]
  skip: true  # [cuda_compiler_version == "11.1"]
  rpaths:
    - lib/
    # conda-forge::pytorch provides these libs
    - {{ SP_DIR }}/torch/lib/
  # weigh down gpu implementation and give nocuda preference
  track_features:
    - cuda_i7khcYiPpQptWags  # [cuda_compiler_version != "None"]

requirements:
  build:
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}  # [cuda_compiler_version != "None"]
  host:
    - python
    - pytorch
    - pytorch =*=cuda*  # [cuda_compiler_version != "None"]
    - pytorch =*=cpu*   # [cuda_compiler_version == "None"]
    - pytorch >=2.1
    - pip
    - setuptools <70.0.0 
  run:
    - python
    - numpy
    #- pyre-extensions ==0.0.29
    - pytorch =*=cuda*  # [cuda_compiler_version != "None"]
    - pytorch =*=cpu*   # [cuda_compiler_version == "None"]

test:
  imports:
    - xformers
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://facebookresearch.github.io/xformers/
  summary: 'XFormers: A collection of composable Transformer building blocks.'
  license: BSD-3-Clause AND Apache-2.0
  license_file:
   - LICENSE
   - third_party/cutlass/LICENSE.txt
   - third_party/flash-attention/LICENSE
   - third_party/sputnik/LICENSE
extra:
  recipe-maintainers:
    - jan-janssen
